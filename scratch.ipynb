{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from llms.config import TrainArgs\n",
    "from llms.llama import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainArgs()\n",
    "transformer = Transformer(args).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embedding): Embedding(16256, 256)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (wq): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (wk): Linear(in_features=256, out_features=32, bias=True)\n",
       "        (wv): Linear(in_features=256, out_features=32, bias=True)\n",
       "        (wo): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (w1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (w2): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (w3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (norm1): RMSNorm()\n",
       "      (norm2): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (output): Linear(in_features=256, out_features=16256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0, 256, (23, 5)).cuda()\n",
    "output = transformer(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\WUSHI\\anaconda3\\envs\\mask2former\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERFACE if_ixml_node_list PUBLIC.\n",
      "\n",
      "  METHODS:\n",
      "    get_length\n",
      "      RETURNING\n",
      "        VALUE(length) TYPE i,\n",
      "    create_iterator\n",
      "      RETURNING VALUE(rval) TYPE REF TO if_ixml_node_iterator,\n",
      "    get_item\n",
      "      IMPORTING\n",
      "        item TYPE if_ixml_node_list\n",
      "      RETURNING\n",
      "        VALUE(val) TYPE REF TO if_ixml_node,\n",
      "    create_rev_iterator_filtered\n",
      "      IMPORTING\n",
      "        filter TYPE any\n",
      "      RETURNING\n",
      "        VALUE(val) TYPE REF TO if_ixml_node_iterator.\n",
      "\n",
      "ENDINTERFACE.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# dataset streaming (will only download the data as needed)\n",
    "ds = load_dataset(\"bigcode/the-stack-dedup\", streaming=True, split=\"train\", token='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')\n",
    "for sample in iter(ds): \n",
    "    print(sample[\"content\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llms.config import TrainArgs as Args\n",
    "from sentencepiece import SentencePieceProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "class TokenizeDataset(IterableDataset):\n",
    "    def __init__(self, args: Args, stream_dataset: IterableDataset):\n",
    "        self.stream_dataset = stream_dataset\n",
    "        self.sp_model = SentencePieceProcessor(model_file=args.tokenizer_model)\n",
    "        self.max_length = args.max_length\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for item in self.stream_dataset:\n",
    "            print(item['content'])\n",
    "            token_list = self.sp_model.encode(item['content'])\n",
    "            print('len(token_list)', len(token_list))\n",
    "            if self.max_length > len(token_list):\n",
    "                token_list.extend([self.sp_model.eos_id()] * (self.max_length - len(token_list)))\n",
    "            else:\n",
    "                start_index = randint(len(token_list) - self.max_length)\n",
    "                token_list = token_list[start_index: start_index + self.max_length]\n",
    "            token_list = np.array(token_list)\n",
    "            yield token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokends = TokenizeDataset(TrainArgs(), ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokends, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERFACE if_ixml_node_list PUBLIC.\n",
      "\n",
      "  METHODS:\n",
      "    get_length\n",
      "      RETURNING\n",
      "        VALUE(length) TYPE i,\n",
      "    create_iterator\n",
      "      RETURNING VALUE(rval) TYPE REF TO if_ixml_node_iterator,\n",
      "    get_item\n",
      "      IMPORTING\n",
      "        item TYPE if_ixml_node_list\n",
      "      RETURNING\n",
      "        VALUE(val) TYPE REF TO if_ixml_node,\n",
      "    create_rev_iterator_filtered\n",
      "      IMPORTING\n",
      "        filter TYPE any\n",
      "      RETURNING\n",
      "        VALUE(val) TYPE REF TO if_ixml_node_iterator.\n",
      "\n",
      "ENDINTERFACE.\n",
      "len(token_list) 178\n",
      "CLASS cx_root DEFINITION ABSTRACT PUBLIC.\n",
      "\n",
      "  PUBLIC SECTION.\n",
      "\n",
      "    INTERFACES if_message.\n",
      "    INTERFACES if_serializable_object.\n",
      "\n",
      "    ALIASES get_longtext FOR if_message~get_longtext.\n",
      "    ALIASES get_text FOR if_message~get_text.\n",
      "\n",
      "    DATA textid TYPE c LENGTH 32.\n",
      "    DATA previous TYPE REF TO cx_root.\n",
      "\n",
      "ENDCLASS.\n",
      "\n",
      "CLASS cx_root IMPLEMENTATION.\n",
      "  METHOD if_message~get_text.\n",
      "    RETURN.\n",
      "  ENDMETHOD.\n",
      "\n",
      "  METHOD if_message~get_longtext.\n",
      "    RETURN.\n",
      "  ENDMETHOD.\n",
      "ENDCLASS.\n",
      "len(token_list) 202\n",
      "FUNCTION transaction_status.\n",
      "  RETURN.\n",
      "ENDFUNCTION.\n",
      "len(token_list) 16\n",
      "tensor([[ 2672,  4945, 29943,  ...,     2,     2,     2],\n",
      "        [  315,  4375,  1799,  ...,     2,     2,     2],\n",
      "        [  383, 28700, 10804,  ...,     2,     2,     2]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "for mm in train_dataloader:\n",
    "    print(mm)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# Set shuffle=True if you need shuffling\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Iterate through the DataLoader\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch)\n",
      "File \u001b[1;32mc:\\Users\\WUSHI\\anaconda3\\envs\\mask2former\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\WUSHI\\anaconda3\\envs\\mask2former\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\WUSHI\\anaconda3\\envs\\mask2former\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:42\u001b[0m, in \u001b[0;36m_IterableDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iter)\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\WUSHI\\anaconda3\\envs\\mask2former\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\WUSHI\\anaconda3\\envs\\mask2former\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:140\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    138\u001b[0m elem_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(it))\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from random import randint\n",
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "class MyIterableDataset(IterableDataset):\n",
    "    def __init__(self):\n",
    "        self.data = [[i for i in range(randint(3, 6))] for _ in range(1000)]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for item in self.data:\n",
    "            yield item\n",
    "\n",
    "# Example: Iterable over a range of numbers\n",
    "dataset = MyIterableDataset()\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=False)  # Set shuffle=True if you need shuffling\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in dataloader:\n",
    "    print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32016"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm.vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = spm.encode('today is sunny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9826, 338, 6575, 1460]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'today is sunny'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm.decode(tokens + [spm.eos_id()] * 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask2former",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
